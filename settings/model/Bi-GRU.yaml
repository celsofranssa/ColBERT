name: Bi-GRU

desc_encoder:
  _target_: source.encoder.GRUEncoder.GRUEncoder
  vocabulary_size: ${model.vocabulary_size}
  representation_size: ${model.hidden_size}
  hidden_size: ${model.hidden_size}
  pooling:
    _target_: source.pooling.AveragePooling.AveragePooling

code_encoder:
  _target_: source.encoder.GRUEncoder.GRUEncoder
  vocabulary_size: ${model.vocabulary_size}
  representation_size: ${model.hidden_size}
  hidden_size: ${model.hidden_size}
  pooling:
    _target_: source.pooling.AveragePooling.AveragePooling

hidden_size: 768
vocabulary_size: 55000

desc_tokenizer:
  architecture: microsoft/codebert-base

code_tokenizer:
  architecture: microsoft/codebert-base

lr: 1e-2
desc_lr: 1e-2
code_lr: 1e-2
base_lr: 5e-4
max_lr: 1e-1
weight_decay: 1e-2

co_training: False
desc_frequency_opt: 1
code_frequency_opt: 1

loss:
  _target_: source.loss.NPairsLoss.NPairsLoss
  params:
    name: N-Pair-Loss