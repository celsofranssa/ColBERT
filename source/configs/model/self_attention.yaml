# @package _group_

name: "self_attention"

desc_encoder: "source.encoder.SelfAttentionEncoder.SelfAttentionEncoder"

desc_encoder_hparams:
  vocabulary_size: 50000
  representation_size: 768
  num_heads: 12
  dropout: 0.1

code_encoder: "source.encoder.SelfAttentionEncoder.SelfAttentionEncoder"

code_encoder_hparams:
  vocabulary_size: 50000
  representation_size: 768
  num_heads: 12
  dropout: 0.1

lr: 1e-5
base_lr: 1e-7
max_lr: 1e-3

loss: "source.loss.TripletLoss.TripletLoss"
loss_hparams:
  name: "TripletLoss"

tokenizer:
  architecture: "bert-base-uncased"

predictions:
  path: "../resources/predictions/self_attention_predictions.pt"