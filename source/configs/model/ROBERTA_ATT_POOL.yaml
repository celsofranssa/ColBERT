# @package _group_

name: "ROBERTA_ATT_POOL"

desc_encoder: "source.encoder.RoBERTaEncoder.RoBERTaEncoder"
desc_encoder_hparams:
  architecture: "roberta-base"
  output_attentions: False
  pooling: "source.pooling.AttentivePooling.AttentivePooling"
  pooling_hparams:
    hidden_size: 768
    max_length: ${data.desc_max_length}


code_encoder: "source.encoder.RoBERTaEncoder.RoBERTaEncoder"
code_encoder_hparams:
  architecture: "roberta-base"
  output_attentions: False
  pooling: "source.pooling.AttentivePooling.AttentivePooling"
  pooling_hparams:
    hidden_size: 768
    max_length: ${data.code_max_length}

lr: 1e-5
base_lr: 1e-7
max_lr: 1e-3
weight_decay: 1e-2

loss: "source.loss.NPairsLoss.NPairsLoss"
loss_hparams:
  name: "NPairsLoss"

tokenizer:
  architecture: "roberta-base"

predictions:
  path: "../resources/predictions/ROBERTA_ATT_POOL_${data.name}predictions.pt"